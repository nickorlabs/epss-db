"""
Shadowserver Exploited-CVE ETL
Downloads and parses the public CSV/JSON feed from Shadowserver to extract exploited CVEs and related metadata.
"""

import os
import json
import logging
import pandas as pd
from playwright.sync_api import sync_playwright

RAW_DATA_DIR = os.environ.get("RAW_DATA_DIR", "/etl-data/raw")
VULN_MONITOR_URL = "https://dashboard.shadowserver.org/statistics/honeypot/vulnerability/monitoring/?category=monitoring&statistic=unique_ips&limit=100000"
DEVICE_MONITOR_URL = "https://dashboard.shadowserver.org/statistics/honeypot/device/monitoring/?category=monitoring&statistic=unique_ips&limit=100000"

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")

def scrape_table_with_playwright(url, base_name):
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()
            logging.info(f"Loading {url}")
            page.goto(url, timeout=60000)
            # Wait for table to appear (assume first <table> is the data table)
            page.wait_for_selector("table", timeout=30000)
            table_html = page.inner_html("table")
            browser.close()
        # Parse table HTML with pandas (wrap in StringIO to avoid FutureWarning)
        from io import StringIO
        html_str = f"<table>{table_html}</table>"
        df_list = pd.read_html(StringIO(html_str))
        if not df_list:
            logging.warning(f"No tables parsed from {url}")
            return None
        df = df_list[0]
        csv_path = os.path.join(RAW_DATA_DIR, f"{base_name}.csv")
        json_path = os.path.join(RAW_DATA_DIR, f"{base_name}.json")
        df.to_csv(csv_path, index=False)
        records = df.astype(str).to_dict(orient="records")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(records, f, ensure_ascii=False, indent=2)
        logging.info(f"Wrote {len(df)} rows to {csv_path} and {json_path}")
        return csv_path, json_path
    except Exception as e:
        logging.error(f"Error scraping {url} with Playwright: {e}")
        return None

def fetch_shadowserver_monitoring():
    scrape_table_with_playwright(VULN_MONITOR_URL, "shadowserver_vulnerability_monitoring")
    scrape_table_with_playwright(DEVICE_MONITOR_URL, "shadowserver_device_monitoring")

if __name__ == "__main__":
    fetch_shadowserver_monitoring()
