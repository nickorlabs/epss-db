import os
import requests
import logging
import csv
import json
import subprocess
import tempfile
from datetime import datetime
RAW_DATA_DIR = os.environ.get("RAW_DATA_DIR", "/etl-data/raw/exploitdb")
NORM_DATA_DIR = os.environ.get("NORM_DATA_DIR", "/etl-data/normalized/exploitdb")
EXPLOITDB_CSV_URL = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv"
EXPLOITDB_REPO = "https://gitlab.com/exploit-database/exploitdb.git"
OUTPUT_CSV = os.path.join(RAW_DATA_DIR, "exploitdb.csv")
OUTPUT_JSON = os.path.join(RAW_DATA_DIR, "exploitdb.json")
OUTPUT_FULL_JSON = os.path.join(RAW_DATA_DIR, f"exploitdb_full_{datetime.now().strftime('%Y%m%d%H%M%S')}.json")
OUTPUT_NORMALIZED_JSON = os.path.join(NORM_DATA_DIR, f"exploitdb_normalized_{datetime.now().strftime('%Y%m%d%H%M%S')}.json")

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")

def fetch_exploitdb():
    # Step 1: Clone or update the repo
    repo_dir = "/etl-data/cache/exploitdb_repo"
    if not os.path.exists(repo_dir):
        logging.info(f"Cloning Exploit-DB repo to {repo_dir}")
        os.makedirs(os.path.dirname(repo_dir), exist_ok=True)
        subprocess.run(["git", "clone", "--depth=1", EXPLOITDB_REPO, repo_dir], check=True)
    else:
        logging.info(f"Updating Exploit-DB repo in {repo_dir}")
        subprocess.run(["git", "-C", repo_dir, "pull"], check=True)

    # Step 2: Download CSV for comparison
    logging.info(f"Downloading Exploit-DB CSV from {EXPLOITDB_CSV_URL}")
    resp = requests.get(EXPLOITDB_CSV_URL, timeout=120)
    resp.raise_for_status()
    with open(OUTPUT_CSV, 'wb') as f:
        f.write(resp.content)
    logging.info(f"Saved Exploit-DB CSV to {OUTPUT_CSV}")

    # Step 3: Parse CSV and combine with exploit files
    with open(OUTPUT_CSV, newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        exploits = list(reader)
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(exploits, f)
    logging.info(f"Extracted and wrote {len(exploits)} Exploit-DB entries to {OUTPUT_JSON}")

    # Step 4: Combine metadata with file content (full JSON)
    full_exploits = []
    for row in exploits:
        exploit_rel_path = row.get('file')
        exploit_abs_path = os.path.join(repo_dir, exploit_rel_path) if exploit_rel_path else None
        code = None
        if exploit_abs_path and os.path.exists(exploit_abs_path):
            try:
                with open(exploit_abs_path, 'r', encoding='utf-8', errors='replace') as ef:
                    code = ef.read()
            except Exception as e:
                logging.warning(f"Failed to read exploit file {exploit_abs_path}: {e}")
        row_with_code = dict(row)
        row_with_code['exploit_code'] = code
        full_exploits.append(row_with_code)
    os.makedirs(os.path.dirname(OUTPUT_FULL_JSON), exist_ok=True)
    with open(OUTPUT_FULL_JSON, 'w', encoding='utf-8') as f:
        json.dump(full_exploits, f)
    logging.info(f"Wrote {len(full_exploits)} full Exploit-DB entries (with code) to {OUTPUT_FULL_JSON}")

    # Step 5: Normalize ExploitDB entries to OSV records
    normalized_exploits = []
    for exploit in full_exploits:
        # Create an OSV record where the OSV id is always the ExploitDB ID (with prefix if needed)
        osv_id = f"EXPLOITDB-{exploit['id']}"
        aliases = []
        # Add CVEs and other cross-referenced IDs (e.g., from 'cve' field) to aliases
        for cve in exploit.get('cve', '').split(','):
            aliases.append(f"CVE-{cve.strip()}")
        # Never use a CVE as the OSV id
        osv_record = {
            'id': osv_id,
            'aliases': aliases,
            'summary': exploit.get('description', ''),
            'details': exploit.get('exploit_code', '')
        }
        normalized_exploits.append(osv_record)
    os.makedirs(os.path.dirname(OUTPUT_NORMALIZED_JSON), exist_ok=True)
    with open(OUTPUT_NORMALIZED_JSON, 'w', encoding='utf-8') as f:
        json.dump(normalized_exploits, f)
    logging.info(f"Wrote {len(normalized_exploits)} normalized Exploit-DB entries to {OUTPUT_NORMALIZED_JSON}")

    # Verification step
    from common import verify
    try:
        verify.verify_record_count(exploits, normalized_exploits)
        # Adjust for normalized ID prefixing: strip 'EXPLOITDB-' from normalized IDs for comparison
        raw_ids = set(str(e.get('id')) for e in exploits if e.get('id'))
        norm_ids = set(str(n.get('id')).replace('EXPLOITDB-', '') for n in normalized_exploits if n.get('id'))
        match = raw_ids == norm_ids
        logging.info(f"Raw IDs count: {len(raw_ids)}, Normalized IDs count: {len(norm_ids)}. IDs match (prefix-insensitive): {match}")
        if not match:
            missing_in_norm = raw_ids - norm_ids
            missing_in_raw = norm_ids - raw_ids
            if missing_in_norm:
                logging.warning(f"IDs present in raw but missing in normalized: {list(missing_in_norm)[:10]}")
            if missing_in_raw:
                logging.warning(f"IDs present in normalized but missing in raw: {list(missing_in_raw)[:10]}")
    except Exception as e:
        logging.warning(f"Verification failed: {e}")

if __name__ == "__main__":
    fetch_exploitdb()
