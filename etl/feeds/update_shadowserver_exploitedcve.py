import os
import requests
import csv
import json
from datetime import datetime
import logging
from io import StringIO

SHADOWSERVER_URL = os.getenv("SHADOWSERVER_URL", "https://sslbl.abuse.ch/blacklist/sslipblacklist.csv")
RAW_DIR = os.getenv("RAW_DIR", "/etl-data/raw/")
NORM_DIR = os.getenv("NORM_DIR", "/etl-data/normalize/")
logging.basicConfig(level=logging.INFO)

def fetch_feed(url):
    resp = requests.get(url, timeout=60)
    resp.raise_for_status()
    return resp.text

def parse_entries(csv_text):
    entries = []
    reader = csv.DictReader(StringIO(csv_text))
    for row in reader:
        entries.append(row)
    return entries

def save_json(data, outdir, prefix):
    os.makedirs(outdir, exist_ok=True)
    ts = datetime.utcnow().strftime("%Y%m%dT%H%M%S")
    path = os.path.join(outdir, f"{prefix}_{ts}.json")
    with open(path, "w") as f:
        json.dump(data, f, indent=2)
    return path

def main():
    logging.info(f"Fetching Shadowserver Exploited-CVE CSV from {SHADOWSERVER_URL}")
    raw = fetch_feed(SHADOWSERVER_URL)
    raw_path = save_json({"raw": raw}, RAW_DIR, "shadowserver_raw")
    logging.info(f"Raw CSV saved to {raw_path}")
    entries = parse_entries(raw)
    norm_path = save_json(entries, NORM_DIR, "shadowserver_norm")
    logging.info(f"Normalized entries saved to {norm_path}")

if __name__ == "__main__":
    main()
